---
title: "Mejora modelo clasificación de vulnerabilidadesB"
author: "Pau Susin Alsina & Pau Guàrdia Sabartés"
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: true
    toc_depth: 5
    toc_float:
      collapsed: true
      smooth_scroll: true
    number_sections: true
    #toc_cols: 4
---

#Mejora modelo clasificación de vulnerabilidades
##Análisis y modificación del Dataset 
El modelo principalmente consiste en encontrar las palabras que más se repiten dentro del campo diagnosis de la base de datos de Qualys, des de el que vamos a intentar predecir si la vulnerabilidad se puede considerar crítica o no solamente leyendo dicho parámetro.
Para hacerlo el modelo encuentra las palabras con mayor freqüencia dentro del campo nombrado anteriormente y aprende sobre ellas. Este hecho nos lleva a pensar que si intentamos normalizar las palabras dentro del propio campo, se puedan conseguir mayores resultados.


```{r setup, include=FALSE}
library(dplyr)
library(tm)
library(caret)
# Read XML document
raw.file = "../../data/qualys/latest.qkdb.xml.zip"
doc <- xml2::read_xml(raw.file)
# Extract QID, SEVERITY_LEVEL and DIAGNOSIS
kdb_txt <- rvest::html_text(rvest::html_elements(doc, xpath="//VULN[DIAGNOSIS]/*[self::QID or self::SEVERITY_LEVEL or self::DIAGNOSIS]"))
kdb_txt <- matrix(kdb_txt, nrow = length(kdb_txt)/3, ncol = 3, byrow = TRUE)
kdb_txt <- as.data.frame.matrix(kdb_txt)
names(kdb_txt) <- c("qid", "severity", "diagnosis")
# Tidy data frame
kdb_txt$qid <- as.integer(kdb_txt$qid)
kdb_txt$severity <- as.integer(kdb_txt$severity)
kdb_txt$diagnosis <- textclean::replace_html(kdb_txt$diagnosis)
kdb_txt$critical <- ifelse(test = kdb_txt$severity < 5, yes = "NO", no = "YES")
kdb_txt$criticalb <- kdb_txt$severity == 5

head(kdb_txt)

# Text analysis
## Stopwords
freq_word <- sort(table(unlist(strsplit(kdb_txt$diagnosis, " "))), decreasing = TRUE)
kdb_words <- names(freq_word)[(which(!(names(freq_word) %in% stopwords::stopwords())))]
## Characters
freq_char <- sort(table(unlist(strsplit(kdb_txt$diagnosis, ""))), decreasing = TRUE)
kdb_txt$descr <- textclean::replace_symbol(kdb_txt$diagnosis)
freq_char2 <- sort(table(unlist(strsplit(kdb_txt$descr, ""))), decreasing = TRUE)
freq_char2
# Prepare data for training
kdb_critical <- kdb_txt %>% filter(critical == "YES")
kdb_other <- kdb_txt %>% filter(critical == "NO")
kdb_ml <- bind_rows(kdb_critical %>% sample_n(2000),
                    kdb_other %>% sample_n(2000)) %>%
          sample_n(4000) %>%
          select(descr, critical)
table(kdb_ml$critical)
```

### Normalización de las muestras
El modelo principalmente consiste en encontrar las palabras que más se repiten dentro del campo diagnosis de la base de datos de Qualys, des de el que vamos a intentar predecir si la vulnerabilidad se puede considerar crítica o no solamente leyendo dicho parámetro.
Para hacerlo el modelo encuentra las palabras con mayor freqüencia dentro del campo nombrado anteriormente y aprende sobre ellas. Este hecho nos lleva a pensar que si intentamos normalizar las palabras dentro del propio campo, se puedan conseguir mayores resultados.

Se ha intentado normalizar todas las palabras que se han encontrado parecidas pero el modelo solo mejora sus resultados con la normalizacion de todos los codigos CVE. Mejora del 1%.

Quizás uno de los metodos que se podria usar seria la implementación de un modelo K-means para clusterizar el máximo de palabras posibles de forma dinàmica. 

```{r norma, include=FALSE}
#*******************************************************************
#                         Classification
#*******************************************************************
# install.packages("tm")
#-------------------------------------------------------------------
#                  4.2.: Preparing data for Classification
#-------------------------------------------------------------------
#Load up the corpus
# course_raw = scan("data/Course-Descriptions.txt", what="", sep="\n")
course_raw <- kdb_ml$descr
course_corpus <- VCorpus(VectorSource(course_raw))
inspect(course_corpus[[1]])
#Convert to lower case
course_corpus2 <- tm_map(course_corpus, content_transformer(tolower))
#Remove punctuations
course_corpus3 <- tm_map(course_corpus2, removePunctuation)
#Remove stopwords
course_corpus4 <- tm_map(course_corpus3, removeWords, stopwords())
#inspect(course_corpus4[[1]])
#Creamos una función para reemplazar palabras
remplazo_palabras <- function(x,palabra_buscar, palabra_reemplazar){
  gsub(palabra_buscar,palabra_reemplazar,x)
}
#Creamos una función para reemplazar palabras con Expresion Regular
remplazo_palabras_re <- function(x,expresion_regular, palabra_reemplazar){
  gsub(expresion_regular,palabra_reemplazar,x, perl = TRUE)
}
  
#Cambiamos Users por user
#course_corpus5 <- tm_map(course_corpus4, content_transformer(remplazo_palabras),palabra_buscar="users",palabra_reemplazar="user")
#Cambiamos vulnerabilities por vulnerability
#course_corpus6 <- tm_map(course_corpus5, content_transformer(remplazo_palabras),palabra_buscar="vulnerabilities",palabra_reemplazar="vulnerability")
#Cambiamos versions por version
#course_corpus7 <- tm_map(course_corpus6, content_transformer(remplazo_palabras),palabra_buscar="versions",palabra_reemplazar="version")
#Cambiamos compromised por compromise
#course_corpus8 <- tm_map(course_corpus7, content_transformer(remplazo_palabras),palabra_buscar="compromised",palabra_reemplazar="compromise")
#Cambiamos corrupted por corrupt
#course_corpus9 <- tm_map(course_corpus8, content_transformer(remplazo_palabras),palabra_buscar="corrupted",palabra_reemplazar="corrupt")
#Cambiamos corruption por corrupt
#course_corpus10 <- tm_map(course_corpus9, content_transformer(remplazo_palabras),palabra_buscar="corruption",palabra_reemplazar="corrupt")
#Aplicamos expresion regular a las palabras "authenticate", "authenticated", "authenticating", "authentication" y las agrupamos a authenticate
#course_corpus11 <- tm_map(course_corpus10, content_transformer(remplazo_palabras_re),expresion_regular="\\bauthentic\\w*\\b",palabra_reemplazar="authenticate")
#Automatically, Automation, Automatic
#course_corpus12 <- tm_map(course_corpus11, content_transformer(remplazo_palabras_re),expresion_regular="\\bautomati\\w*\\b",palabra_reemplazar="automatic")
#Cambiamos systems por system
#course_corpus14 <- tm_map(course_corpus13, content_transformer(remplazo_palabras),palabra_buscar="systems",palabra_reemplazar="system")
#Cambiamos issues por issue
#course_corpus15 <- tm_map(course_corpus14, content_transformer(remplazo_palabras),palabra_buscar="issues",palabra_reemplazar="issue")
#Cambiamos fixes por fix
#course_corpus16 <- tm_map(course_corpus15, content_transformer(remplazo_palabras),palabra_buscar="fixes",palabra_reemplazar="fix")
#Cambiamos files por file
#course_corpus17 <- tm_map(course_corpus16, content_transformer(remplazo_palabras),palabra_buscar="files",palabra_reemplazar="file")
#No interesa un CVE especifico sino simplemente que esta asociado a un CVE.
course_corpus5 <- tm_map(course_corpus4, content_transformer(remplazo_palabras_re),expresion_regular="\\bcve\\w*\\b",palabra_reemplazar="cve_id")
#Generate TF-IDF matrix
course_dtm <- DocumentTermMatrix(course_corpus5)
findFreqTerms(course_dtm,5)
#Remove terms not in 90% of the documents. Only have those that are there
#in atleast 10% documents
dense_course_dtm <- removeSparseTerms(course_dtm, .85)
#Inspect to TF-IDF
inspect(dense_course_dtm)
#Convert continuous values to classes = { Yes, No }
conv_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0)
  x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}
class_dtm <- apply(dense_course_dtm, MARGIN = 2, conv_counts)
```


##Muestras de entreno
El objetico de este punto es evaluar el % de muestras criticas a usar a la hora de entrenar el modelo.
Observando la base de datos de Qualys nos damos cuenta que existen muchas más vulnerabilidades definidas como no críticas que aquellas definidas como críticas. Por lo que seguramente el porcentaje de muestras críticas usadas para el entreno debe ser menor al de no críticas.

Otro valor a determinar es el número de muestras que se utiliza para entrenar el modelo. Con el fin de determinar la mejor combinación de ambos valores se realizarán varios gráficos de Accuracy-Porcentaje de muestras críticas para determinar el mejor porcentaje con el cuál se obtiene una mejor accuracy para cada número de muestras.

La primera prueba que se ha realizado, contiene un número total de muetstras de entrenamiento igual a 4000. Se han evaluado los porcentajes 5,10,20,30,40 y 50 de muestras críticas, por el hecho mencionado anteriormente. 

```{r porcen, include=FALSE, echo=FALSE}
total <- 4000
porcentajes <- c(0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5)
accuracies <- numeric()
for (x in porcentajes){
  
  print(x*total)
  print((1-x)*total)
  
  kdb_ml <- bind_rows(kdb_critical %>% sample_n(x*total),
                      kdb_other %>% sample_n((1-x)*total)) %>%
    sample_n(total) %>%
    select(descr, critical)
  
  
  #*******************************************************************
  #                         Classification
  #*******************************************************************
  # install.packages("tm")
  #-------------------------------------------------------------------
  #                  4.2.: Preparing data for Classification
  #-------------------------------------------------------------------
  #Load up the corpus
  # course_raw = scan("data/Course-Descriptions.txt", what="", sep="\n")
  course_raw <- kdb_ml$descr
  course_corpus <- VCorpus(VectorSource(course_raw))
  inspect(course_corpus[[1]])
  #Convert to lower case
  course_corpus2 <- tm_map(course_corpus, content_transformer(tolower))
  #Remove punctuations
  course_corpus3 <- tm_map(course_corpus2, removePunctuation)
  #Remove stopwords
  course_corpus4 <- tm_map(course_corpus3, removeWords, stopwords())
  
  #Creamos una función para reemplazar palabras con Expresion Regular
  remplazo_palabras_re <- function(x,expresion_regular, palabra_reemplazar){
    gsub(expresion_regular,palabra_reemplazar,x, perl = TRUE)
  }
  
  #No interesa un CVE especifico sino simplemente que esta asociado a un CVE.
  course_corpus5 <- tm_map(course_corpus4, content_transformer(remplazo_palabras_re),expresion_regular="\\bcve\\w*\\b",palabra_reemplazar="cve_id")
  
  
  #Generate TF-IDF matrix
  course_dtm <- DocumentTermMatrix(course_corpus4)
  
  findFreqTerms(course_dtm,5)
  #Remove terms not in 90% of the documents. Only have those that are there
  #in atleast 2 documents
  dense_course_dtm <- removeSparseTerms(course_dtm, .85)
  #Inspect to TF-IDF
  
  #Convert continuous values to classes = { Yes, No }
  conv_counts <- function(x) {
    x <- ifelse(x > 0, 1, 0)
    x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
  }
  class_dtm <- apply(dense_course_dtm, MARGIN = 2, conv_counts)
  
  #-------------------------------------------------------------------
  #                  4.3.: Building the model
  #-------------------------------------------------------------------
  #Load the classifications for the descriptions
  # course_classes = scan("data/Course-Classification.txt", what="", sep="\n")
  course_classes <- kdb_ml$critical
  #install.packages("caret")
  #Random split of training and testing sets
  train_set <- createDataPartition(y=course_classes, p=.7,list=FALSE)
  #spliting the dtm
  train_dtm <- class_dtm[train_set,]
  test_dtm <-class_dtm[-train_set,]
  #split the course_classes
  train_classes <- course_classes[train_set]
  test_classes <- course_classes[-train_set]
  #train the model using naive bayes
  course_model <- train( data.frame(train_dtm), train_classes, method="nb")
  
  #-------------------------------------------------------------------
  #                  4.3.: Predictions for Text
  #-------------------------------------------------------------------
  #Predict for the test data
  course_predictions <- predict(course_model,test_dtm)
  #Analyze prediction accuracy
  confusionMatrix(table(course_predictions , test_classes))
  #-------------------------------------------------------------------
  accuracies <- c(accuracies, confusionMatrix(table(course_predictions , test_classes))$overall["Accuracy"])
}
```

```{r plot,echo=FALSE}
plot(porcentajes, accuracies, col = "blue", type="o")
lines(porcentajes,accuracies)
title("Evaluación Accuracy vs Porcentaje muestras criticas")
```

Los resultados obtenidos son muy significativos. Tal y como se observa, si usamos un porcentaje menor de muestras críticas, los resultados mejoran. Aun así cabe destacar el resultado obtenido con el 5% de muestras críticas. Cuando se entrena el modelo con un 5% de muestras críticas y un 95% de muestras no críticas, se obtiene un accuracy del 92% aproximadamente. Este hecho se debe a que estamos entrenando al modelo a saber determinar de forma muy correcta todas aquellas muestras que NO son críticas, y por consecuencia, puede determinar de forma muy correcta las que si que lo son.

Con los resultados anteriores, los valores que se evaluarán de porcentaje a partir de ahora serán (5%, 10%, 15%, 20% y 25%). A continuación podemos observar todos los gráficos que vamos a obtener 

```{r totales, fig.show="only", include=FALSE}
totales <- c(2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000)
porcentajes <- c(0.05, 0.1, 0.15, 0.2, 0.25)
accuracies <- numeric()
for (total in totales){
  print (total)
  for (x in porcentajes){
    
    print(x*total)
    print((1-x)*total)
    
    kdb_ml <- bind_rows(kdb_critical %>% sample_n(x*total),
                        kdb_other %>% sample_n((1-x)*total)) %>%
      sample_n(total) %>%
      select(descr, critical)
    
    
    #*******************************************************************
    #                         Classification
    #*******************************************************************
    # install.packages("tm")
    #-------------------------------------------------------------------
    #                  4.2.: Preparing data for Classification
    #-------------------------------------------------------------------
    #Load up the corpus
    # course_raw = scan("data/Course-Descriptions.txt", what="", sep="\n")
    course_raw <- kdb_ml$descr
    course_corpus <- VCorpus(VectorSource(course_raw))
    inspect(course_corpus[[1]])
    #Convert to lower case
    course_corpus2 <- tm_map(course_corpus, content_transformer(tolower))
    #Remove punctuations
    course_corpus3 <- tm_map(course_corpus2, removePunctuation)
    #Remove stopwords
    course_corpus4 <- tm_map(course_corpus3, removeWords, stopwords())
    
    #Creamos una función para reemplazar palabras con Expresion Regular
    remplazo_palabras_re <- function(x,expresion_regular, palabra_reemplazar){
      gsub(expresion_regular,palabra_reemplazar,x, perl = TRUE)
    }
    
    #No interesa un CVE especifico sino simplemente que esta asociado a un CVE.
    course_corpus5 <- tm_map(course_corpus4, content_transformer(remplazo_palabras_re),expresion_regular="\\bcve\\w*\\b",palabra_reemplazar="cve_id")
    
    
    #Generate TF-IDF matrix
    course_dtm <- DocumentTermMatrix(course_corpus4)
    
    findFreqTerms(course_dtm,5)
    #Remove terms not in 90% of the documents. Only have those that are there
    #in atleast 2 documents
    dense_course_dtm <- removeSparseTerms(course_dtm, .85)
    #Inspect to TF-IDF
    
    #Convert continuous values to classes = { Yes, No }
    conv_counts <- function(x) {
      x <- ifelse(x > 0, 1, 0)
      x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
    }
    class_dtm <- apply(dense_course_dtm, MARGIN = 2, conv_counts)
    
    #-------------------------------------------------------------------
    #                  4.3.: Building the model
    #-------------------------------------------------------------------
    #Load the classifications for the descriptions
    # course_classes = scan("data/Course-Classification.txt", what="", sep="\n")
    course_classes <- kdb_ml$critical
    #install.packages("caret")
    #Random split of training and testing sets
    train_set <- createDataPartition(y=course_classes, p=.7,list=FALSE)
    #spliting the dtm
    train_dtm <- class_dtm[train_set,]
    test_dtm <-class_dtm[-train_set,]
    #split the course_classes
    train_classes <- course_classes[train_set]
    test_classes <- course_classes[-train_set]
    #train the model using naive bayes
    course_model <- train( data.frame(train_dtm), train_classes, method="nb")
    
    #-------------------------------------------------------------------
    #                  4.3.: Predictions for Text
    #-------------------------------------------------------------------
    #Predict for the test data
    course_predictions <- predict(course_model,test_dtm)
    #Analyze prediction accuracy
    confusionMatrix(table(course_predictions , test_classes))
    #-------------------------------------------------------------------
    accuracies <- c(accuracies, confusionMatrix(table(course_predictions , test_classes))$overall["Accuracy"])
  }
  print("Total 1")
  plot(porcentajes, accuracies, col = "blue", type="o")
  text(porcentajes, accuracies, labels = round(accuracies, 2), pos = 3)
  lines(porcentajes,accuracies)
  title(paste("Evaluación Accuracy vs Porcentaje muestras criticas. N=", total))
  accuracies <- numeric()
}
```

