---
title: "Mejora modelo clasificación de vulnerabilidadesB"
author: "Pau Susin Alsina & Pau Guàrdia Sabartés"
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: true
    toc_depth: 5
    toc_float:
      collapsed: true
      smooth_scroll: true
    number_sections: true
    #toc_cols: 4
    
  pdf_document: default
---

#Mejora modelo clasificación de vulnerabilidades
##Análisis y modificación del Dataset
El método que vamos a seguir es ir mirando en la tabla class_dtm (que contiene las 24 palabras que se van a usar para la detección) aquellas palabras que són muy similares que pueden ser lo mismo.
En este punto lo que se va a realizar es modificar una de las palabras por la otra (considerando que son la misma).

```{r setup, include=false}
library(dplyr)
library(tm)
library(caret)
# Read XML document
raw.file = "../../data/qualys/latest.qkdb.xml.zip"
doc <- xml2::read_xml(raw.file)
# Extract QID, SEVERITY_LEVEL and DIAGNOSIS
kdb_txt <- rvest::html_text(rvest::html_elements(doc, xpath="//VULN[DIAGNOSIS]/*[self::QID or self::SEVERITY_LEVEL or self::DIAGNOSIS]"))
kdb_txt <- matrix(kdb_txt, nrow = length(kdb_txt)/3, ncol = 3, byrow = TRUE)
kdb_txt <- as.data.frame.matrix(kdb_txt)
names(kdb_txt) <- c("qid", "severity", "diagnosis")
# Tidy data frame
kdb_txt$qid <- as.integer(kdb_txt$qid)
kdb_txt$severity <- as.integer(kdb_txt$severity)
kdb_txt$diagnosis <- textclean::replace_html(kdb_txt$diagnosis)
kdb_txt$critical <- ifelse(test = kdb_txt$severity < 5, yes = "NO", no = "YES")
kdb_txt$criticalb <- kdb_txt$severity == 5
# Text analysis
## Stopwords
freq_word <- sort(table(unlist(strsplit(kdb_txt$diagnosis, " "))), decreasing = TRUE)
kdb_words <- names(freq_word)[(which(!(names(freq_word) %in% stopwords::stopwords())))]
## Characters
freq_char <- sort(table(unlist(strsplit(kdb_txt$diagnosis, ""))), decreasing = TRUE)
kdb_txt$descr <- textclean::replace_symbol(kdb_txt$diagnosis)
freq_char2 <- sort(table(unlist(strsplit(kdb_txt$descr, ""))), decreasing = TRUE)
freq_char2
# Prepare data for training
kdb_critical <- kdb_txt %>% filter(critical == "YES")
kdb_other <- kdb_txt %>% filter(critical == "NO")
kdb_ml <- bind_rows(kdb_critical %>% sample_n(3000),
                    kdb_other %>% sample_n(12000)) %>%
          sample_n(15000) %>%
          select(descr, critical)
table(kdb_ml$critical)
#*******************************************************************
#                         Classification
#*******************************************************************
# install.packages("tm")
#-------------------------------------------------------------------
#                  4.2.: Preparing data for Classification
#-------------------------------------------------------------------
#Load up the corpus
# course_raw = scan("data/Course-Descriptions.txt", what="", sep="\n")
course_raw <- kdb_ml$descr
course_corpus <- VCorpus(VectorSource(course_raw))
inspect(course_corpus[[1]])
#Convert to lower case
course_corpus2 <- tm_map(course_corpus, content_transformer(tolower))
#Remove punctuations
course_corpus3 <- tm_map(course_corpus2, removePunctuation)
#Remove stopwords
course_corpus4 <- tm_map(course_corpus3, removeWords, stopwords())
#inspect(course_corpus4[[1]])


#Creamos una función para reemplazar palabras
remplazo_palabras <- function(x,palabra_buscar, palabra_reemplazar){
  gsub(palabra_buscar,palabra_reemplazar,x)
}

#Creamos una función para reemplazar palabras con Expresion Regular
remplazo_palabras_re <- function(x,expresion_regular, palabra_reemplazar){
  gsub(expresion_regular,palabra_reemplazar,x, perl = TRUE)
}


#Cambiamos Users por user
course_corpus5 <- tm_map(course_corpus4, content_transformer(remplazo_palabras),palabra_buscar="users",palabra_reemplazar="user")


#Cambiamos vulnerabilities por vulnerability
course_corpus6 <- tm_map(course_corpus5, content_transformer(remplazo_palabras),palabra_buscar="vulnerabilities",palabra_reemplazar="vulnerability")


#Cambiamos versions por version
course_corpus7 <- tm_map(course_corpus6, content_transformer(remplazo_palabras),palabra_buscar="versions",palabra_reemplazar="version")

#Cambiamos compromised por compromise
course_corpus8 <- tm_map(course_corpus7, content_transformer(remplazo_palabras),palabra_buscar="compromised",palabra_reemplazar="compromise")

#Cambiamos corrupted por corrupt
course_corpus9 <- tm_map(course_corpus8, content_transformer(remplazo_palabras),palabra_buscar="corrupted",palabra_reemplazar="corrupt")

#Cambiamos corruption por corrupt
course_corpus10 <- tm_map(course_corpus9, content_transformer(remplazo_palabras),palabra_buscar="corruption",palabra_reemplazar="corrupt")

#Aplicamos expresion regular a las palabras "authenticate", "authenticated", "authenticating", "authentication" y las agrupamos a authenticate
course_corpus11 <- tm_map(course_corpus10, content_transformer(remplazo_palabras_re),expresion_regular="\\bauthentic\\w*\\b",palabra_reemplazar="authenticate")

#Automatically, Automation, Automatic
course_corpus12 <- tm_map(course_corpus11, content_transformer(remplazo_palabras_re),expresion_regular="\\bautomati\\w*\\b",palabra_reemplazar="automatic")

#No interesa un CVE especifico sino simplemente que esta asociado a un CVE.
course_corpus13 <- tm_map(course_corpus12, content_transformer(remplazo_palabras_re),expresion_regular="\\bcve\\w*\\b",palabra_reemplazar="cve")

#Cambiamos systems por system
course_corpus14 <- tm_map(course_corpus13, content_transformer(remplazo_palabras),palabra_buscar="systems",palabra_reemplazar="system")

#Cambiamos issues por issue
course_corpus15 <- tm_map(course_corpus14, content_transformer(remplazo_palabras),palabra_buscar="issues",palabra_reemplazar="issue")

#Cambiamos fixes por fix
course_corpus16 <- tm_map(course_corpus15, content_transformer(remplazo_palabras),palabra_buscar="fixes",palabra_reemplazar="fix")

#Cambiamos files por file
course_corpus17 <- tm_map(course_corpus16, content_transformer(remplazo_palabras),palabra_buscar="files",palabra_reemplazar="file")

#No interesa un CVE especifico sino simplemente que esta asociado a un CVE.
course_corpus18 <- tm_map(course_corpus17, content_transformer(remplazo_palabras_re),expresion_regular="\\b\\d+cve\\d+\\b",palabra_reemplazar="cve")

#Generate TF-IDF matrix
course_dtm <- DocumentTermMatrix(course_corpus18)
findFreqTerms(course_dtm,5)

#Remove terms not in 90% of the documents. Only have those that are there
#in atleast 10% documents
dense_course_dtm <- removeSparseTerms(course_dtm, .85)
#Inspect to TF-IDF
inspect(dense_course_dtm)
#Convert continuous values to classes = { Yes, No }
conv_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0)
  x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}
class_dtm <- apply(dense_course_dtm, MARGIN = 2, conv_counts)
```


##Muestras de entreno
El objetico de este punto es evaluar el % de muestras criticas a usar a la hora de entrenar el modelo.
Observando la base de datos de Qualys nos damos cuenta que existen muchas más vulnerabilidades definidas como no críticas que aquellas definidas como críticas. Por lo que seguramente el porcentaje de muestras críticas usadas para el entreno debe ser menor al de no críticas.

Se creará un gráfico que muestre cuál es el mejor porcentaje a usar para obtener una mejor accuracy.


##Optimizar los parámetros del modelo

##Modificación del modelo (n-gramas)
En vez de utilizar palabras para la detección, usar la concanetación de palabras.
